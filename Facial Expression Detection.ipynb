{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from typing import List\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "filename = 'dataset/emotions_dataset.csv'\n",
    "df = pd.read_csv(filename, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"
   },
   "outputs": [],
   "source": [
    "df_train = df[(df.usage == 'Training') | (df.usage == 'PublicTest')].copy().reset_index()\n",
    "df_train['labels'] = [label_map[e] for e in df_train.emotion]\n",
    "\n",
    "df_test = df[df.usage == 'PrivateTest'].copy().reset_index()\n",
    "df_test['labels'] = [label_map[e] for e in df_test.emotion]\n",
    "del df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfde4d91ff367dfa6764202c1b309ea291fb833a"
   },
   "outputs": [],
   "source": [
    "def pixels_to_images(pixels_series: pd.Series) -> np.ndarray:\n",
    "    pixels_lists = [[int(n) for n in p.split()] for p in pixels_series]\n",
    "    X = np.array(pixels_lists) / 255\n",
    "    X = X.reshape(-1, 48, 48, 1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_data = 'dataset/numpy_images.npy'\n",
    "if Path(npy_data).is_file():\n",
    "    with open('dataset/numpy_images.npy', 'rb') as f:\n",
    "        X = np.load(f)\n",
    "else:\n",
    "    X = pixels_to_images(df_train.pixels)\n",
    "    with open('dataset/numpy_images.npy', 'wb') as f:\n",
    "        np.save(f, X)\n",
    "\n",
    "X_test = pixels_to_images(df_test.pixels)\n",
    "\n",
    "Y = df_train.emotion.astype(int).to_list()\n",
    "y_test = df_test.emotion.astype(int).to_list()\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "435d0e06553e3de3fd982e4a4a86c28018ac3913"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 4\n",
    "rows = 5\n",
    "true_labels = []\n",
    "preds = []\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_id = np.random.choice(X.shape[0])\n",
    "    img = X[img_id, :, :, 0]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    true_labels.append(df_train.labels.iloc[img_id])\n",
    "    preds.append(true_labels[i-1])\n",
    "    plt.title(f\"{true_labels[i-1]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be4faef86c3c5635697f10939547edd5c8760308"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3afd36886a65ff49fe48ac73271f7477b574375a"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8eaecce539d06c983ed73142ac1484dbfa5e970"
   },
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optim = tf.keras.optimizers.Adam(learning_rate=2e-4)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=optim)\n",
    "    \n",
    "    return model\n",
    "model=my_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5004be413385dbdf6c3967d34c59e541095ea667"
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,  # set range for random shear\n",
    "    zoom_range=0.0,  # set range for random zoom\n",
    "    channel_shift_range=0.0,  # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,  # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,  # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=\"channels_last\",\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0,\n",
    ")\n",
    "image_generator = image_generator.flow(X_train, y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5004be413385dbdf6c3967d34c59e541095ea667"
   },
   "outputs": [],
   "source": [
    "val_generator = ImageDataGenerator()\n",
    "val_generator = val_generator.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5004be413385dbdf6c3967d34c59e541095ea667",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_model='checkpoints/{epoch:02d}-{val_loss:.6f}.hdf5'\n",
    "Path('checkpoints').mkdir(parents=True, exist_ok=True)\n",
    "h = model.fit(\n",
    "    x=image_generator, \n",
    "    steps_per_epoch=len(X_train) // 64,\n",
    "    epochs=100, \n",
    "    verbose=1, \n",
    "    validation_data=val_generator,\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(filepath=path_model),\n",
    "        EarlyStopping(patience=15),\n",
    "        ReduceLROnPlateau(patience=6, factor=0.3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "077d44e8bbb7549a09682eb09c417903bf2fd935"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "077d44e8bbb7549a09682eb09c417903bf2fd935"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 4\n",
    "rows = 5\n",
    "true_labels = []\n",
    "preds = []\n",
    "preds = model.predict(X_test)\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_id = np.random.choice(X_test.shape[0])\n",
    "    img = X_test[img_id, :, :, 0]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.title(f\"{label_map[y_test[img_id]]}, {label_map[np.argmax(preds[img_id])]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "077d44e8bbb7549a09682eb09c417903bf2fd935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = load_model('artifacts/34-0.953775.hdf5')\n",
    "\n",
    "prototxtPath = \"face_detector/deploy.prototxt\"\n",
    "weightsPath = \"face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('dataset/example_images/surprised.jpg')\n",
    "orig = image.copy()\n",
    "(h, w) = image.shape[:2]\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# loop over the detections\n",
    "for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    if confidence > 0.5:\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        (startX, startY) = (max(0, startX), max(0, startY))\n",
    "        (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "        height = endY - startY\n",
    "        \n",
    "        midX = int((endX + startX) / 2)\n",
    "        # extract the face ROI, convert it from BGR to RGB channel\n",
    "        # ordering, resize it to 224x224, and preprocess it\n",
    "        face = image[startY:endY, (midX - int(height / 2)):(midX + int(height / 2))]\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        face = cv2.resize(face, (48, 48))\n",
    "        face = img_to_array(face)\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "\n",
    "        # pass the face through the model to determine if the face\n",
    "        # has a mask or not\n",
    "        preds = model.predict(face)[0]\n",
    "\n",
    "        # determine the class label and color we'll use to draw\n",
    "        # the bounding box and text\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "        # include the probability in the label\n",
    "        label = \"{}: {:.2f}%\".format(label_map[np.argmax(preds)], max(preds) * 100)\n",
    "\n",
    "        # display the label and bounding box rectangle on the output\n",
    "        # frame\n",
    "        cv2.putText(image, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "cv2.imshow(\"Output\", image)\n",
    "while True:\n",
    "    key = cv2.waitKey(0)\n",
    "    if key in [27, ord('q'), ord('Q')]:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(face[0,:,:,:]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "077d44e8bbb7549a09682eb09c417903bf2fd935"
   },
   "outputs": [],
   "source": [
    "def emotion_analysis(emotions):\n",
    "    y_pos = np.arange(len(label_map))\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n",
    "    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n",
    "    plt.xticks(y_pos, label_map)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "241291244491cc1e84a45ecb0da66c1c09a4cd7a"
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "#print(y_pred)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e97d2cb00640d2bfc4d4de9456249e893f72cc2"
   },
   "outputs": [],
   "source": [
    "#import seaborn as sn\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#%matplotlib inline\n",
    "#cm = confusion_matrix(np.where(y_test == 1)[1], y_pred)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#df_cm = pd.DataFrame(cm, index = [i for i in \"0123456\"],\n",
    "                  #columns = [i for i in \"0123456\"])\n",
    "#plt.figure(figsize = (20,15))\n",
    "#sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real Time Expression Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70fc48e66d18c54ba629e625ad8def5ad2d93fa6"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "img = image.load_img('../input/myimage/Shawon.jpg', grayscale=True, target_size=(48, 48))\n",
    "show_img = image.load_img('../input/myimage/Shawon.jpg', grayscale=False, target_size=(200, 200))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "custom = model.predict(x)\n",
    "#print(custom[0])\n",
    "emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(show_img)\n",
    "plt.show()\n",
    "\n",
    "m=0.000000000000000000001\n",
    "a=custom[0]\n",
    "for i in range(0,len(a)):\n",
    "    if a[i]>m:\n",
    "        m=a[i]\n",
    "        ind=i\n",
    "        \n",
    "print('Expression Prediction:',objects[ind])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Live Demo of Production Level Project**\n",
    "\n",
    "[Facial Expression Detection Web App](https://faceai.herokuapp.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expression_detector",
   "language": "python",
   "name": "expression_detector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
